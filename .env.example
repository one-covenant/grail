# ============================================================================
# NETWORK SELECTION (used by code in grail/shared/constants.py and network helper)
# ============================================================================
# Which Bittensor network to connect to:
# - finney : mainnet
# - test   : public testnet
# - custom : use BT_CHAIN_ENDPOINT below
BT_NETWORK=finney

# Optional explicit websocket endpoint (use for private/custom nodes)
# Example: wss://test.finney.opentensor.ai:443
BT_CHAIN_ENDPOINT=

# Your target subnet NETUID (e.g., 81 mainnet, 429 your test subnet)
NETUID=81

# ============================================================================
# WALLET CONFIGURATION
# ============================================================================
# These are *names* (aliases) you assign when creating the coldkey and hotkey.
# You can create a new one for mining/validating like `btcli wallet new_coldkey --wallet.name mywallet`
# Not the SS58 address or file path. Just the user-chosen wallet name.
# 1. BT_WALLET_COLD — the name you gave your coldkey (e.g., "mywallet")
# This key stays offline and is used for staking, registration, and ownership.
BT_WALLET_COLD=

# 2. BT_WALLET_HOT — the name you gave your hotkey (e.g., "myhotkey")
# You can create a new one `btcli wallet new_hotkey --wallet.name mywallet --wallet.hotkey myhotkey`
# Note that mywallet here is the same from the previous set.
# This key is safe to use online and used for mining, validation, or inference.
BT_WALLET_HOT=default

# ============================================================================
# REQUIRED: STORAGE (Cloudflare R2) - DUAL CREDENTIAL SYSTEM
# ============================================================================
# IMPORTANT: GRAIL uses a dual-credential system for R2:
# - WRITE credentials: Private, never shared, used for uploading your data
# - READ credentials: Shared on-chain, allows others to read your data

# 1. R2_BUCKET_ID: The name of the R2 bucket you create
# ➤ Go to https://dash.cloudflare.com > R2 > "Create Bucket"
# ➤ Choose a unique bucket name (e.g., `validator-artifacts`) — this is your BUCKET_ID.
R2_BUCKET_ID=""

# 2. R2_ACCOUNT_ID: Your Cloudflare account ID (used in API endpoints)
# ➤ Go to: https://dash.cloudflare.com > Click your account (top left) > Overview
# ➤ Copy the "Account ID" shown there.
R2_ACCOUNT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# 3. WRITE CREDENTIALS (Private - NEVER shared on chain)
# These are your API credentials with full read/write access to R2
# ➤ Go to: https://dash.cloudflare.com > R2 > "Manage R2 API Tokens"
# ➤ Click "Create API Token"
# ➤ Name it something like "grail-write-access"
# ➤ Select **Edit Permissions**, and:
#   - Scope: `Account.Cloudflare R2 Storage` (or select R2 bucket explicitly)
#   - Permissions: `Edit` (for full read/write access)
# ➤ Generate and copy both keys.
R2_WRITE_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXXXXX
R2_WRITE_SECRET_ACCESS_KEY=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# 4. READ CREDENTIALS (Public - Will be posted to chain)
# These are API credentials with read-only access to R2
# ➤ Go to: https://dash.cloudflare.com > R2 > "Manage R2 API Tokens"
# ➤ Click "Create API Token" again
# ➤ Name it something like "grail-read-only"
# ➤ Select **Read Permissions**, and:
#   - Scope: `Account.Cloudflare R2 Storage` (or select R2 bucket explicitly)
#   - Permissions: `Read` (for read-only access)
# ➤ Generate and copy both keys.
# NOTE: These credentials will be committed to the blockchain for transparency
R2_READ_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXXXXX
R2_READ_SECRET_ACCESS_KEY=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# ============================================================================
# OPTIONAL: HUGGING FACE
# ============================================================================

# 5. HF_TOKEN: Your Hugging Face access token for uploading datasets
# ➤ Go to: https://huggingface.co/settings/tokens
# ➤ Click "New token" and create a token with write permissions
# ➤ Copy the token (starts with hf_...)
# This is used to upload validated rollouts to the public Hugging Face dataset
HF_TOKEN=hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# 6. HF_USERNAME: Your Hugging Face username (optional)
# ➤ This is your HuggingFace username (e.g., "fatheroffire")
# ➤ The dataset will be created at: {HF_USERNAME}/grail-sat-rollouts
# ➤ If not set, defaults to "fatheroffire"
HF_USERNAME=miahi

# ============================================================================
# GRAIL MODEL CONFIGURATION
# ============================================================================
# HuggingFace model name to use for GRAIL operations
GRAIL_MODEL_NAME=Qwen/Qwen3-4B-Instruct-2507

# Maximum number of new tokens to generate during inference
GRAIL_MAX_NEW_TOKENS=1024

# Number of rollouts to generate per problem (for GRPO training)
# IMPORTANT: Fixed at 4 for this release. Do NOT change.
GRAIL_ROLLOUTS_PER_PROBLEM=4

# ============================================================================
# MONITORING SYSTEM CONFIGURATION
# ============================================================================
# Backend type for monitoring ("wandb" for WandB, "null" to disable)
GRAIL_MONITORING_BACKEND=wandb

# ============================================================================
# WANDB (WEIGHTS & BIASES) CONFIGURATION
# ============================================================================
# WandB API key (create at https://wandb.ai/settings)
# Required for WANDB_MODE="online"
WANDB_API_KEY=
# WandB project name (creates a project in your WandB workspace)
WANDB_PROJECT=grail

# WandB entity/team name (your username or team name, optional)
WANDB_ENTITY=tplr

# WandB mode - controls how data is sent to WandB
# - "online": Send data to WandB cloud in real-time (production)
# - "offline": Store data locally, sync later with: wandb sync
# - "disabled": Disable WandB completely
WANDB_MODE=online

# Tags for organizing runs (comma-separated)
WANDB_TAGS=grail,bittensor,production

# Description/notes for runs
WANDB_NOTES=GRAIL production monitoring

# Resume behavior for interrupted runs
# - "allow": Resume if possible, create new otherwise
# - "must": Must resume existing run (fails if not found)
# - "never": Always create new run
# - "auto": Automatically resume based on run ID
WANDB_RESUME=allow

# ============================================================================
# MONITORING PERFORMANCE TUNING
# ============================================================================
# Number of metrics to buffer before flushing to WandB (default: 100)
# Higher values = less network calls but more memory usage
GRAIL_METRIC_BUFFER_SIZE=100

# Interval in seconds between automatic metric flushes (default: 30.0)
# Lower values = more real-time data but more network overhead
GRAIL_METRIC_FLUSH_INTERVAL=30.0


# ============================================================================
# OBSERVABILITY (Grafana + Loki via Promtail) [Optional]
# ============================================================================
# IMPORTANT: This section is completely optional. Only configure if you want
# centralized logging and monitoring with Grafana + Loki.
#
# Use Promtail to ship logs to Loki for better reliability
# and performance. The app writes logs locally; Promtail tails and forwards them.
#
# SETUP REQUIREMENTS:
# 1. Deploy Grafana + Loki on a separate server using:
#    docker-compose --env-file .env -f docker/compose.grafana.yaml up -d
# 2. Configure PROMTAIL_LOKI_URL to point to your Loki instance
# 3. Set GRAIL_ENV and ensure your wallet/network vars are configured
# 4. Set GRAIL_LOG_FILE to enable file logging for Promtail to tail
#
# Promtail will automatically use labels from your environment:
# - env (from GRAIL_ENV), service=grail, network (from BT_NETWORK)
# - netuid (from NETUID), wallet (from BT_WALLET_COLD), hotkey (from BT_WALLET_HOT)
#
# If you don't want observability, set PROMTAIL_ENABLE=false

# Enable Promtail-based log shipping (required for Grafana logging)
PROMTAIL_ENABLE=false

# Loki push endpoint URL for Promtail (replace with your Grafana/Loki server)
# Example: http://your-grafana-server.com:3100/loki/api/v1/push
PROMTAIL_LOKI_URL=http://loki:3100/loki/api/v1/push

# Job name for Promtail scraping
PROMTAIL_JOB=grail

# App log file path (required for Promtail tailing)
# Promtail will tail this file and ship logs to Loki
GRAIL_LOG_FILE=/var/log/grail/grail.log

# Optional: log rotation for file logging (used by RotatingFileHandler)
# Accepts bytes or units: KB, MB, GB (e.g., 100MB)
GRAIL_LOG_MAX_SIZE=100MB
# Number of rotated log files to keep
GRAIL_LOG_BACKUP_COUNT=5

# Environment label for promtail logs (dev, staging, prod, etc.)
GRAIL_ENV=prod

# Grafana server root URL (used when deploying Grafana with compose.grafana.yaml)
# This should match the public URL where your Grafana instance will be accessible
# Default: http://localhost:3000 (if not set)
# GF_SERVER_ROOT_URL=http://your-grafana-server.com:3000
